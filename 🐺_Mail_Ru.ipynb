{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "🐺 Mail.Ru.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "miv2Og-_-ohj",
        "colab_type": "code",
        "outputId": "1e89b736-c37a-436f-f149-f66b8a5d243e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        }
      },
      "source": [
        "!pip install pytorch-pretrained-bert\n",
        "# !pip install pandas\n",
        "# !pip install torch\n",
        "# !pip install nltk\n",
        "# !pip install tqdm\n",
        "# !pip install seaborn\n",
        "# !pip install numpy\n",
        "# !pip install sklearn\n",
        "import torch\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from nltk.tokenize import word_tokenize, wordpunct_tokenize\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "import re\n",
        "import torch.nn as nn\n",
        "import math\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch-pretrained-bert in /usr/local/lib/python3.6/dist-packages (0.6.2)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.3.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2.21.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2019.12.9)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.10.40)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.17.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (4.28.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2019.11.28)\n",
            "Requirement already satisfied: botocore<1.14.0,>=1.13.40 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (1.13.40)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.2.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.9.4)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.40->boto3->pytorch-pretrained-bert) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.40->boto3->pytorch-pretrained-bert) (2.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\"->botocore<1.14.0,>=1.13.40->boto3->pytorch-pretrained-bert) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbC-2RFPaqbN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for instance in list(tqdm._instances):\n",
        "    tqdm._decr_instances(instance)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OS7qcbLQ74Q2",
        "colab_type": "code",
        "outputId": "094b2b71-3597-414a-a635-f90dd4c8a94a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from google.colab import files, drive\n",
        "drive.mount('/content/gdrive')\n",
        "# torch.save(encoder1.state_dict(), \"gdrive/My Drive/CompLing/rusdeu10_beam_encoder1.dic\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "DI4HBch763y3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
        "\n",
        "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
        "import logging\n",
        "# logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "bertpath = 'gdrive/My Drive/CompLing/rubert'\n",
        "# Load pre-trained model tokenizer (vocabulary)\n",
        "tokenizer = BertTokenizer.from_pretrained(bertpath, do_lower_case=False)\n",
        "modelbert = BertModel.from_pretrained(bertpath)\n",
        "modelbert.cuda()\n",
        "\n",
        "\n",
        "\n",
        "def get_embedding(text):       \n",
        "    marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
        "    # Tokenize our sentence with the BERT tokenizer.\n",
        "    tokenized_text = tokenizer.tokenize(marked_text)\n",
        "    # Print out the tokens.\n",
        "    # print (tokenized_text)\n",
        "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "    segments_ids = [1] * len(tokenized_text)\n",
        "    \n",
        "    # Display the words with their indeces.\n",
        "    # for tup in zip(tokenized_text, indexed_tokens):\n",
        "    #     print('{:<12} {:>6,}'.format(tup[0], tup[1]))\n",
        "    tokens_tensor = torch.tensor([indexed_tokens])\n",
        "    segments_tensors = torch.tensor([segments_ids])\n",
        "\n",
        "    tokens_tensor.cuda()\n",
        "    segments_tensors.cuda()\n",
        "    # print(tokens_tensor)\n",
        "    # Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
        "    modelbert.eval()\n",
        "    # Predict hidden states features for each layer\n",
        "    with torch.no_grad():\n",
        "        encoded_layers, _ = modelbert(tokens_tensor, segments_tensors)   \n",
        "    # Stores the token vectors, with shape [22 x 3,072]\n",
        "    token_vecs_cat = []\n",
        "    # `token_embeddings` is a [22 x 12 x 768] tensor.\n",
        "    token_embeddings = torch.stack(encoded_layers, dim=0)\n",
        "    token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
        "    token_embeddings = token_embeddings.permute(1, 0, 2)\n",
        "#     print(token_embeddings.shape)\n",
        "    # For each token in the sentence...\n",
        "    for token in token_embeddings:\n",
        "        # `token` is a [12 x 768] tensor\n",
        "        # Concatenate the vectors (that is, append them together) from the last \n",
        "        # four layers.\n",
        "        # Each layer vector is 768 values, so `cat_vec` is length 3,072.\n",
        "        cat_vec = torch.cat((token[-1], token[-2], token[-3], token[-4]), dim=0)    \n",
        "    # Use `cat_vec` to represent `token`.\n",
        "    token_vecs_cat.append(cat_vec)\n",
        "    # print ('Shape is: %d x %d' % (len(token_vecs_cat), len(token_vecs_cat[0])))    \n",
        "    return torch.stack(token_vecs_cat, dim=0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "cuPIFtMA63zL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# the_sentence = \"Слон съел банан.\"\n",
        "# the_bert_emb = get_embedding(the_sentence)\n",
        "# print(the_bert_emb.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "A6cmQ8VK63za",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv('gdrive/My Drive/CompLing/mailru_train.csv')\n",
        "test = pd.read_csv('gdrive/My Drive/CompLing/mailru_test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "jfVhb_ac630D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "puncts  = str.maketrans('','',\":,?;\\\"!.«»()\\'\\*\\+\\\\\\/\\>\\<\\=\")\n",
        "def smart_process_text(b):\n",
        "    b = re.sub(r\"(?<=[А-ЯЁа-яё\\dA-Za-z])(?=\\))\", \" \", b)    \n",
        "    eyes, noses, mouths = r\":;8BX=\", r\"-~'^\", r\")(/\\|DP\"\n",
        "    patsmileys = \"[%s][%s]?[%s]\" % tuple(map(re.escape, [eyes, noses, mouths]))\n",
        "    j = re.findall(patsmileys, b)\n",
        "    patsmile = r\"\\s\\)+\"\n",
        "    h = re.findall(patsmile, b)\n",
        "#     b = re.sub(r\"\\?\", \" СПРАШИВАЮ \", b)\n",
        "#     b = re.sub(r\"\\!\", \" ВАЖНО \", b)\n",
        "    if j:\n",
        "        b = re.sub(patsmileys, \" УЛЫБАЮСЬ \", b)\n",
        "    # print (j, b)\n",
        "    if h and b.count('(') == 0:\n",
        "        b = re.sub(patsmile, \" УЛЫБАЮСЬ \", b)\n",
        "    \n",
        "    b = re.sub(r\"о_о|o_o\", \" УДИВЛЯЮСЬ и УЛЫБАЮСЬ \", b, flags=re.IGNORECASE)\n",
        "    b = re.sub(r\"\\)+\\++\", \" ШУЧУ \", b)    \n",
        "    b = re.sub(r\"\\)\\)\\)*\", \" СМЕЮСЬ \", b)\n",
        "    b = re.sub(r\"\\(\\(\\(*\", \" ПОМОГИТЕ \", b)    \n",
        "    b  = re.sub(r\"\\?\", \" СПРАШИВАЮ \", b)\n",
        "    b  = re.sub(r\"\\$\", \" ДОЛЛАР \", b)\n",
        "    b  = re.sub(r\"\\)\\=\", \" МАТЕМАТИКА \", b)\n",
        "\n",
        "    # specific\n",
        "    b  = re.sub(r\"✿‿✿\", \" ШУТКА ЮМОРА \", b) \n",
        "    b  = re.sub(r\"\\(\\+\\)\", \" ВОПРОС \", b) \n",
        "    b  = re.sub(r\"хорар\", \" гороскоп \", b, flags=re.IGNORECASE) \n",
        "    b  = re.sub(r\"плез\", \" очень пожалуйста \", b, flags=re.IGNORECASE)     \n",
        "    b  = re.sub(r\"ryzen|райзен.*\", \" процессор \", b, flags=re.IGNORECASE) \n",
        "    b  = re.sub(r\"rtx\", \" видеокарта \", b, flags=re.IGNORECASE)     \n",
        "    b  = re.sub(r\"тдв\", \" темы для взрослых \", b, flags=re.IGNORECASE) \n",
        "    b  = re.sub(r\"безобманство\", \" глупая религия \", b, flags=re.IGNORECASE)     \n",
        "    b  = re.sub(r\"PascalABC.*\", \" плохой язык программирования \", b, flags=re.IGNORECASE) \n",
        "    b  = re.sub(r\"python.*\", \" хороший язык программирования \", b, flags=re.IGNORECASE) \n",
        "    b  = re.sub(r\"крмп|п[ау]бг.*|pubg|фортнайт.*|fortnite|roblox|роблокс.*|discord|дискорд.*\", \" компьютерная игра \", b, flags=re.IGNORECASE) \n",
        "    b  = re.sub(r\"зеленск[огмийу]+\", \" президент Украины \", b, flags=re.IGNORECASE) \n",
        "    b  = re.sub(r\"дошик.*\", \" плохие макароны \", b, flags=re.IGNORECASE) \n",
        "    b  = re.sub(r\"eлeна\", \" Елена любительница астрологии и магии \", b, flags=re.IGNORECASE) \n",
        "    b  = re.sub(r\"☼\\)\\s+☼\\)\\s+☼\\)\", \" загадка \", b)\n",
        "    b  = re.sub(r\"Девчин\", \" любовь \", b) # https://otvet.mail.ru/profile/id51163161/\n",
        "    b = re.sub(r\"\\!\", \" ВАЖНО \", b)\n",
        "    b = re.sub(r\"\\+\\+\\+*\", \" СОГЛАШАЮСЬ \", b)\n",
        "    b = re.sub(r\"%\", \" процентов \", b)\n",
        "    b = re.sub(r\"°\\s*[CС]\", \" градусов Цельсия \", b)\n",
        "    b = re.sub(r\"°\", \" градусов \", b)\n",
        "    b = re.sub(r\"\\\"\", \"\", b)\n",
        "    \n",
        "    words = wordpunct_tokenize(b.lower())    \n",
        "    return words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "mX0ni1KB630N",
        "colab_type": "code",
        "outputId": "e5aa967c-aa0c-4b2d-bd3f-825a88f00692",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "word2freq = {}\n",
        "\n",
        "for question in tqdm(train.question):    \n",
        "    words = smart_process_text(question)    \n",
        "    for word in words:        \n",
        "        if word in word2freq:\n",
        "            word2freq[word] += 1\n",
        "        else:\n",
        "            word2freq[word] = 1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/666666 [00:00<?, ?it/s]\u001b[A\n",
            "  0%|          | 999/666666 [00:00<01:06, 9988.58it/s]\u001b[A\n",
            "  0%|          | 2225/666666 [00:00<01:02, 10576.18it/s]\u001b[A\n",
            "  1%|          | 3401/666666 [00:00<01:00, 10903.14it/s]\u001b[A\n",
            "  1%|          | 4610/666666 [00:00<00:58, 11233.77it/s]\u001b[A\n",
            "  1%|          | 5815/666666 [00:00<00:57, 11466.36it/s]\u001b[A\n",
            "  1%|          | 6925/666666 [00:00<00:58, 11353.08it/s]\u001b[A\n",
            "  1%|          | 8131/666666 [00:00<00:56, 11555.95it/s]\u001b[A\n",
            "  1%|▏         | 9414/666666 [00:00<00:55, 11906.64it/s]\u001b[A\n",
            "  2%|▏         | 10615/666666 [00:00<00:54, 11935.23it/s]\u001b[A\n",
            "  2%|▏         | 11784/666666 [00:01<00:55, 11857.04it/s]\u001b[A\n",
            "  2%|▏         | 12945/666666 [00:01<00:57, 11412.88it/s]\u001b[A\n",
            "  2%|▏         | 14196/666666 [00:01<00:55, 11721.19it/s]\u001b[A\n",
            "  2%|▏         | 15491/666666 [00:01<00:53, 12063.44it/s]\u001b[A\n",
            "  3%|▎         | 16736/666666 [00:01<00:53, 12175.62it/s]\u001b[A\n",
            "  3%|▎         | 18015/666666 [00:01<00:52, 12351.01it/s]\u001b[A\n",
            "  3%|▎         | 19289/666666 [00:01<00:51, 12463.71it/s]\u001b[A\n",
            "  3%|▎         | 20557/666666 [00:01<00:51, 12524.80it/s]\u001b[A\n",
            "  3%|▎         | 21814/666666 [00:01<00:51, 12538.02it/s]\u001b[A\n",
            "  3%|▎         | 23068/666666 [00:01<00:52, 12200.04it/s]\u001b[A\n",
            "  4%|▎         | 24290/666666 [00:02<00:52, 12201.47it/s]\u001b[A\n",
            "  4%|▍         | 25512/666666 [00:02<00:53, 11914.52it/s]\u001b[A\n",
            "  4%|▍         | 26737/666666 [00:02<00:53, 12011.22it/s]\u001b[A\n",
            "  4%|▍         | 27941/666666 [00:02<00:53, 11886.78it/s]\u001b[A\n",
            "  4%|▍         | 29180/666666 [00:02<00:52, 12033.09it/s]\u001b[A\n",
            "  5%|▍         | 30402/666666 [00:02<00:52, 12087.26it/s]\u001b[A\n",
            "  5%|▍         | 31612/666666 [00:02<00:54, 11728.48it/s]\u001b[A\n",
            "  5%|▍         | 32837/666666 [00:02<00:53, 11878.74it/s]\u001b[A\n",
            "  5%|▌         | 34075/666666 [00:02<00:52, 12022.93it/s]\u001b[A\n",
            "  5%|▌         | 35280/666666 [00:02<00:52, 12003.07it/s]\u001b[A\n",
            "  5%|▌         | 36482/666666 [00:03<00:53, 11855.33it/s]\u001b[A\n",
            "  6%|▌         | 37670/666666 [00:03<00:54, 11535.09it/s]\u001b[A\n",
            "  6%|▌         | 38841/666666 [00:03<00:54, 11586.21it/s]\u001b[A\n",
            "  6%|▌         | 40028/666666 [00:03<00:53, 11669.86it/s]\u001b[A\n",
            "  6%|▌         | 41252/666666 [00:03<00:52, 11834.28it/s]\u001b[A\n",
            "  6%|▋         | 42518/666666 [00:03<00:51, 12068.71it/s]\u001b[A\n",
            "  7%|▋         | 43787/666666 [00:03<00:50, 12247.27it/s]\u001b[A\n",
            "  7%|▋         | 45014/666666 [00:03<00:51, 12185.81it/s]\u001b[A\n",
            "  7%|▋         | 46254/666666 [00:03<00:50, 12249.24it/s]\u001b[A\n",
            "  7%|▋         | 47481/666666 [00:03<00:50, 12245.25it/s]\u001b[A\n",
            "  7%|▋         | 48707/666666 [00:04<00:53, 11531.33it/s]\u001b[A\n",
            "  7%|▋         | 49870/666666 [00:04<00:55, 11045.41it/s]\u001b[A\n",
            "  8%|▊         | 50986/666666 [00:04<00:56, 10870.36it/s]\u001b[A\n",
            "  8%|▊         | 52208/666666 [00:04<00:54, 11238.36it/s]\u001b[A\n",
            "  8%|▊         | 53514/666666 [00:04<00:52, 11728.79it/s]\u001b[A\n",
            "  8%|▊         | 54761/666666 [00:04<00:51, 11940.26it/s]\u001b[A\n",
            "  8%|▊         | 55999/666666 [00:04<00:50, 12065.33it/s]\u001b[A\n",
            "  9%|▊         | 57245/666666 [00:04<00:50, 12176.91it/s]\u001b[A\n",
            "  9%|▉         | 58492/666666 [00:04<00:49, 12263.30it/s]\u001b[A\n",
            "  9%|▉         | 59727/666666 [00:05<00:49, 12287.36it/s]\u001b[A\n",
            "  9%|▉         | 60959/666666 [00:05<00:49, 12241.34it/s]\u001b[A\n",
            "  9%|▉         | 62185/666666 [00:05<00:50, 11965.61it/s]\u001b[A\n",
            " 10%|▉         | 63387/666666 [00:05<00:50, 11981.62it/s]\u001b[A\n",
            " 10%|▉         | 64676/666666 [00:05<00:49, 12238.57it/s]\u001b[A\n",
            " 10%|▉         | 65928/666666 [00:05<00:48, 12321.18it/s]\u001b[A\n",
            " 10%|█         | 67163/666666 [00:05<00:48, 12290.22it/s]\u001b[A\n",
            " 10%|█         | 68394/666666 [00:05<00:48, 12281.87it/s]\u001b[A\n",
            " 10%|█         | 69716/666666 [00:05<00:47, 12546.78it/s]\u001b[A\n",
            " 11%|█         | 70996/666666 [00:05<00:47, 12619.83it/s]\u001b[A\n",
            " 11%|█         | 72260/666666 [00:06<00:47, 12615.86it/s]\u001b[A\n",
            " 11%|█         | 73523/666666 [00:06<00:47, 12484.89it/s]\u001b[A\n",
            " 11%|█         | 74773/666666 [00:06<00:49, 12014.68it/s]\u001b[A\n",
            " 11%|█▏        | 76014/666666 [00:06<00:48, 12129.74it/s]\u001b[A\n",
            " 12%|█▏        | 77231/666666 [00:06<00:48, 12109.40it/s]\u001b[A\n",
            " 12%|█▏        | 78458/666666 [00:06<00:48, 12155.67it/s]\u001b[A\n",
            " 12%|█▏        | 79687/666666 [00:06<00:48, 12194.57it/s]\u001b[A\n",
            " 12%|█▏        | 80950/666666 [00:06<00:47, 12321.23it/s]\u001b[A\n",
            " 12%|█▏        | 82228/666666 [00:06<00:46, 12455.08it/s]\u001b[A\n",
            " 13%|█▎        | 83475/666666 [00:06<00:47, 12295.63it/s]\u001b[A\n",
            " 13%|█▎        | 84741/666666 [00:07<00:46, 12402.57it/s]\u001b[A\n",
            " 13%|█▎        | 86039/666666 [00:07<00:46, 12565.81it/s]\u001b[A\n",
            " 13%|█▎        | 87297/666666 [00:07<00:48, 12063.06it/s]\u001b[A\n",
            " 13%|█▎        | 88509/666666 [00:07<00:47, 12074.45it/s]\u001b[A\n",
            " 13%|█▎        | 89721/666666 [00:07<00:48, 12012.43it/s]\u001b[A\n",
            " 14%|█▎        | 91009/666666 [00:07<00:46, 12259.88it/s]\u001b[A\n",
            " 14%|█▍        | 92286/666666 [00:07<00:46, 12406.73it/s]\u001b[A\n",
            " 14%|█▍        | 93530/666666 [00:07<00:46, 12416.55it/s]\u001b[A\n",
            " 14%|█▍        | 94802/666666 [00:07<00:45, 12505.77it/s]\u001b[A\n",
            " 14%|█▍        | 96071/666666 [00:07<00:45, 12556.38it/s]\u001b[A\n",
            " 15%|█▍        | 97330/666666 [00:08<00:45, 12563.25it/s]\u001b[A\n",
            " 15%|█▍        | 98588/666666 [00:08<00:45, 12542.37it/s]\u001b[A\n",
            " 15%|█▍        | 99843/666666 [00:08<00:48, 11612.14it/s]\u001b[A\n",
            " 15%|█▌        | 101068/666666 [00:08<00:47, 11795.82it/s]\u001b[A\n",
            " 15%|█▌        | 102292/666666 [00:08<00:47, 11925.31it/s]\u001b[A\n",
            " 16%|█▌        | 103558/666666 [00:08<00:46, 12135.80it/s]\u001b[A\n",
            " 16%|█▌        | 104814/666666 [00:08<00:45, 12258.28it/s]\u001b[A\n",
            " 16%|█▌        | 106045/666666 [00:08<00:45, 12232.47it/s]\u001b[A\n",
            " 16%|█▌        | 107316/666666 [00:08<00:45, 12371.41it/s]\u001b[A\n",
            " 16%|█▋        | 108607/666666 [00:08<00:44, 12528.04it/s]\u001b[A\n",
            " 16%|█▋        | 109875/666666 [00:09<00:44, 12570.47it/s]\u001b[A\n",
            " 17%|█▋        | 111158/666666 [00:09<00:43, 12646.81it/s]\u001b[A\n",
            " 17%|█▋        | 112424/666666 [00:09<00:45, 12189.41it/s]\u001b[A\n",
            " 17%|█▋        | 113667/666666 [00:09<00:45, 12258.88it/s]\u001b[A\n",
            " 17%|█▋        | 114939/666666 [00:09<00:44, 12393.49it/s]\u001b[A\n",
            " 17%|█▋        | 116181/666666 [00:09<00:44, 12280.04it/s]\u001b[A\n",
            " 18%|█▊        | 117447/666666 [00:09<00:44, 12390.54it/s]\u001b[A\n",
            " 18%|█▊        | 118711/666666 [00:09<00:43, 12462.15it/s]\u001b[A\n",
            " 18%|█▊        | 119959/666666 [00:09<00:43, 12440.37it/s]\u001b[A\n",
            " 18%|█▊        | 121204/666666 [00:10<00:44, 12252.33it/s]\u001b[A\n",
            " 18%|█▊        | 122459/666666 [00:10<00:44, 12338.82it/s]\u001b[A\n",
            " 19%|█▊        | 123729/666666 [00:10<00:43, 12441.00it/s]\u001b[A\n",
            " 19%|█▊        | 124975/666666 [00:10<00:44, 12065.70it/s]\u001b[A\n",
            " 19%|█▉        | 126222/666666 [00:10<00:44, 12181.17it/s]\u001b[A\n",
            " 19%|█▉        | 127496/666666 [00:10<00:43, 12343.31it/s]\u001b[A\n",
            " 19%|█▉        | 128735/666666 [00:10<00:43, 12357.08it/s]\u001b[A\n",
            " 19%|█▉        | 129974/666666 [00:10<00:43, 12364.81it/s]\u001b[A\n",
            " 20%|█▉        | 131212/666666 [00:10<00:43, 12242.04it/s]\u001b[A\n",
            " 20%|█▉        | 132466/666666 [00:10<00:43, 12327.98it/s]\u001b[A\n",
            " 20%|██        | 133732/666666 [00:11<00:42, 12424.19it/s]\u001b[A\n",
            " 20%|██        | 135011/666666 [00:11<00:42, 12530.96it/s]\u001b[A\n",
            " 20%|██        | 136265/666666 [00:11<00:42, 12339.92it/s]\u001b[A\n",
            " 21%|██        | 137501/666666 [00:11<00:45, 11753.69it/s]\u001b[A\n",
            " 21%|██        | 138699/666666 [00:11<00:44, 11819.05it/s]\u001b[A\n",
            " 21%|██        | 139915/666666 [00:11<00:44, 11918.57it/s]\u001b[A\n",
            " 21%|██        | 141124/666666 [00:11<00:43, 11968.62it/s]\u001b[A\n",
            " 21%|██▏       | 142349/666666 [00:11<00:43, 12050.67it/s]\u001b[A\n",
            " 22%|██▏       | 143564/666666 [00:11<00:43, 12077.26it/s]\u001b[A\n",
            " 22%|██▏       | 144789/666666 [00:11<00:43, 12127.34it/s]\u001b[A\n",
            " 22%|██▏       | 146004/666666 [00:12<00:42, 12130.72it/s]\u001b[A\n",
            " 22%|██▏       | 147218/666666 [00:12<00:42, 12101.64it/s]\u001b[A\n",
            " 22%|██▏       | 148429/666666 [00:12<00:43, 11810.62it/s]\u001b[A\n",
            " 22%|██▏       | 149612/666666 [00:12<00:44, 11582.26it/s]\u001b[A\n",
            " 23%|██▎       | 150886/666666 [00:12<00:43, 11906.45it/s]\u001b[A\n",
            " 23%|██▎       | 152081/666666 [00:12<00:43, 11845.56it/s]\u001b[A\n",
            " 23%|██▎       | 153317/666666 [00:12<00:42, 11994.18it/s]\u001b[A\n",
            " 23%|██▎       | 154542/666666 [00:12<00:42, 12066.26it/s]\u001b[A\n",
            " 23%|██▎       | 155818/666666 [00:12<00:41, 12263.72it/s]\u001b[A\n",
            " 24%|██▎       | 157094/666666 [00:12<00:41, 12406.06it/s]\u001b[A\n",
            " 24%|██▍       | 158351/666666 [00:13<00:40, 12453.60it/s]\u001b[A\n",
            " 24%|██▍       | 159598/666666 [00:13<00:40, 12380.49it/s]\u001b[A\n",
            " 24%|██▍       | 160838/666666 [00:13<00:40, 12354.13it/s]\u001b[A\n",
            " 24%|██▍       | 162075/666666 [00:13<00:41, 12066.54it/s]\u001b[A\n",
            " 24%|██▍       | 163284/666666 [00:13<00:42, 11982.30it/s]\u001b[A\n",
            " 25%|██▍       | 164507/666666 [00:13<00:41, 12052.45it/s]\u001b[A\n",
            " 25%|██▍       | 165800/666666 [00:13<00:40, 12301.92it/s]\u001b[A\n",
            " 25%|██▌       | 167043/666666 [00:13<00:40, 12339.23it/s]\u001b[A\n",
            " 25%|██▌       | 168279/666666 [00:13<00:41, 12136.66it/s]\u001b[A\n",
            " 25%|██▌       | 169567/666666 [00:13<00:40, 12350.25it/s]\u001b[A\n",
            " 26%|██▌       | 170818/666666 [00:14<00:39, 12397.67it/s]\u001b[A\n",
            " 26%|██▌       | 172109/666666 [00:14<00:39, 12544.70it/s]\u001b[A\n",
            " 26%|██▌       | 173365/666666 [00:14<00:39, 12384.43it/s]\u001b[A\n",
            " 26%|██▌       | 174605/666666 [00:14<00:42, 11511.66it/s]\u001b[A\n",
            " 26%|██▋       | 175770/666666 [00:14<00:43, 11272.70it/s]\u001b[A\n",
            " 27%|██▋       | 176920/666666 [00:14<00:43, 11339.38it/s]\u001b[A\n",
            " 27%|██▋       | 178062/666666 [00:14<00:43, 11205.37it/s]\u001b[A\n",
            " 27%|██▋       | 179235/666666 [00:14<00:42, 11356.82it/s]\u001b[A\n",
            " 27%|██▋       | 180450/666666 [00:14<00:41, 11581.53it/s]\u001b[A\n",
            " 27%|██▋       | 181665/666666 [00:15<00:41, 11744.74it/s]\u001b[A\n",
            " 27%|██▋       | 182843/666666 [00:15<00:41, 11672.46it/s]\u001b[A\n",
            " 28%|██▊       | 184013/666666 [00:15<00:41, 11544.96it/s]\u001b[A\n",
            " 28%|██▊       | 185266/666666 [00:15<00:40, 11822.28it/s]\u001b[A\n",
            " 28%|██▊       | 186452/666666 [00:15<00:41, 11696.20it/s]\u001b[A\n",
            " 28%|██▊       | 187755/666666 [00:15<00:39, 12066.31it/s]\u001b[A\n",
            " 28%|██▊       | 189028/666666 [00:15<00:38, 12255.98it/s]\u001b[A\n",
            " 29%|██▊       | 190258/666666 [00:15<00:38, 12232.79it/s]\u001b[A\n",
            " 29%|██▊       | 191485/666666 [00:15<00:39, 12004.34it/s]\u001b[A\n",
            " 29%|██▉       | 192689/666666 [00:15<00:39, 11891.88it/s]\u001b[A\n",
            " 29%|██▉       | 193905/666666 [00:16<00:39, 11970.37it/s]\u001b[A\n",
            " 29%|██▉       | 195135/666666 [00:16<00:39, 12065.40it/s]\u001b[A\n",
            " 29%|██▉       | 196374/666666 [00:16<00:38, 12160.75it/s]\u001b[A\n",
            " 30%|██▉       | 197592/666666 [00:16<00:38, 12129.37it/s]\u001b[A\n",
            " 30%|██▉       | 198806/666666 [00:16<00:39, 11765.76it/s]\u001b[A\n",
            " 30%|███       | 200110/666666 [00:16<00:38, 12119.21it/s]\u001b[A\n",
            " 30%|███       | 201344/666666 [00:16<00:38, 12184.11it/s]\u001b[A\n",
            " 30%|███       | 202574/666666 [00:16<00:37, 12214.51it/s]\u001b[A\n",
            " 31%|███       | 203798/666666 [00:16<00:38, 12137.35it/s]\u001b[A\n",
            " 31%|███       | 205014/666666 [00:16<00:38, 12075.79it/s]\u001b[A\n",
            " 31%|███       | 206223/666666 [00:17<00:39, 11697.34it/s]\u001b[A\n",
            " 31%|███       | 207397/666666 [00:17<00:39, 11702.43it/s]\u001b[A\n",
            " 31%|███▏      | 208654/666666 [00:17<00:38, 11945.74it/s]\u001b[A\n",
            " 31%|███▏      | 209929/666666 [00:17<00:37, 12175.12it/s]\u001b[A\n",
            " 32%|███▏      | 211150/666666 [00:17<00:38, 11820.74it/s]\u001b[A\n",
            " 32%|███▏      | 212378/666666 [00:17<00:38, 11954.25it/s]\u001b[A\n",
            " 32%|███▏      | 213658/666666 [00:17<00:37, 12194.46it/s]\u001b[A\n",
            " 32%|███▏      | 214948/666666 [00:17<00:36, 12397.02it/s]\u001b[A\n",
            " 32%|███▏      | 216192/666666 [00:17<00:36, 12264.76it/s]\u001b[A\n",
            " 33%|███▎      | 217422/666666 [00:17<00:37, 12079.56it/s]\u001b[A\n",
            " 33%|███▎      | 218638/666666 [00:18<00:37, 12101.75it/s]\u001b[A\n",
            " 33%|███▎      | 219850/666666 [00:18<00:37, 11807.29it/s]\u001b[A\n",
            " 33%|███▎      | 221089/666666 [00:18<00:37, 11975.80it/s]\u001b[A\n",
            " 33%|███▎      | 222290/666666 [00:18<00:37, 11830.32it/s]\u001b[A\n",
            " 34%|███▎      | 223476/666666 [00:18<00:38, 11545.14it/s]\u001b[A\n",
            " 34%|███▎      | 224768/666666 [00:18<00:37, 11922.09it/s]\u001b[A\n",
            " 34%|███▍      | 226080/666666 [00:18<00:35, 12256.91it/s]\u001b[A\n",
            " 34%|███▍      | 227376/666666 [00:18<00:35, 12458.46it/s]\u001b[A\n",
            " 34%|███▍      | 228627/666666 [00:18<00:36, 11965.80it/s]\u001b[A\n",
            " 34%|███▍      | 229865/666666 [00:19<00:36, 12084.91it/s]\u001b[A\n",
            " 35%|███▍      | 231145/666666 [00:19<00:35, 12287.45it/s]\u001b[A\n",
            " 35%|███▍      | 232433/666666 [00:19<00:34, 12458.26it/s]\u001b[A\n",
            " 35%|███▌      | 233683/666666 [00:19<00:35, 12329.41it/s]\u001b[A\n",
            " 35%|███▌      | 234920/666666 [00:19<00:34, 12340.05it/s]\u001b[A\n",
            " 35%|███▌      | 236157/666666 [00:19<00:35, 12145.47it/s]\u001b[A\n",
            " 36%|███▌      | 237457/666666 [00:19<00:34, 12387.60it/s]\u001b[A\n",
            " 36%|███▌      | 238743/666666 [00:19<00:34, 12523.20it/s]\u001b[A\n",
            " 36%|███▌      | 240036/666666 [00:19<00:33, 12640.68it/s]\u001b[A\n",
            " 36%|███▌      | 241302/666666 [00:19<00:34, 12378.78it/s]\u001b[A\n",
            " 36%|███▋      | 242543/666666 [00:20<00:34, 12274.50it/s]\u001b[A\n",
            " 37%|███▋      | 243773/666666 [00:20<00:35, 12022.77it/s]\u001b[A\n",
            " 37%|███▋      | 245040/666666 [00:20<00:34, 12207.35it/s]\u001b[A\n",
            " 37%|███▋      | 246314/666666 [00:20<00:34, 12360.71it/s]\u001b[A\n",
            " 37%|███▋      | 247553/666666 [00:20<00:34, 12034.46it/s]\u001b[A\n",
            " 37%|███▋      | 248760/666666 [00:20<00:35, 11869.78it/s]\u001b[A\n",
            " 38%|███▊      | 250033/666666 [00:20<00:34, 12111.67it/s]\u001b[A\n",
            " 38%|███▊      | 251299/666666 [00:20<00:33, 12269.38it/s]\u001b[A\n",
            " 38%|███▊      | 252529/666666 [00:20<00:33, 12202.45it/s]\u001b[A\n",
            " 38%|███▊      | 253761/666666 [00:20<00:33, 12235.61it/s]\u001b[A\n",
            " 38%|███▊      | 255019/666666 [00:21<00:33, 12335.55it/s]\u001b[A\n",
            " 38%|███▊      | 256254/666666 [00:21<00:33, 12295.26it/s]\u001b[A\n",
            " 39%|███▊      | 257485/666666 [00:21<00:33, 12170.12it/s]\u001b[A\n",
            " 39%|███▉      | 258735/666666 [00:21<00:33, 12266.88it/s]\u001b[A\n",
            " 39%|███▉      | 260040/666666 [00:21<00:32, 12490.74it/s]\u001b[A\n",
            " 39%|███▉      | 261291/666666 [00:21<00:33, 12088.50it/s]\u001b[A\n",
            " 39%|███▉      | 262504/666666 [00:21<00:33, 11967.96it/s]\u001b[A\n",
            " 40%|███▉      | 263803/666666 [00:21<00:32, 12256.02it/s]\u001b[A\n",
            " 40%|███▉      | 265033/666666 [00:21<00:32, 12226.92it/s]\u001b[A\n",
            " 40%|███▉      | 266259/666666 [00:21<00:33, 12056.15it/s]\u001b[A\n",
            " 40%|████      | 267468/666666 [00:22<00:33, 12002.45it/s]\u001b[A\n",
            " 40%|████      | 268670/666666 [00:22<00:33, 11843.93it/s]\u001b[A\n",
            " 40%|████      | 269925/666666 [00:22<00:32, 12045.28it/s]\u001b[A\n",
            " 41%|████      | 271132/666666 [00:22<00:32, 12042.50it/s]\u001b[A\n",
            " 41%|████      | 272418/666666 [00:22<00:32, 12276.00it/s]\u001b[A\n",
            " 41%|████      | 273648/666666 [00:22<00:32, 12088.46it/s]\u001b[A\n",
            " 41%|████      | 274893/666666 [00:22<00:32, 12193.65it/s]\u001b[A\n",
            " 41%|████▏     | 276120/666666 [00:22<00:31, 12215.74it/s]\u001b[A\n",
            " 42%|████▏     | 277394/666666 [00:22<00:31, 12367.30it/s]\u001b[A\n",
            " 42%|████▏     | 278662/666666 [00:23<00:31, 12457.45it/s]\u001b[A\n",
            " 42%|████▏     | 279909/666666 [00:23<00:31, 12442.07it/s]\u001b[A\n",
            " 42%|████▏     | 281169/666666 [00:23<00:30, 12487.98it/s]\u001b[A\n",
            " 42%|████▏     | 282419/666666 [00:23<00:31, 12135.74it/s]\u001b[A\n",
            " 43%|████▎     | 283636/666666 [00:23<00:31, 12038.11it/s]\u001b[A\n",
            " 43%|████▎     | 284871/666666 [00:23<00:31, 12127.66it/s]\u001b[A\n",
            " 43%|████▎     | 286086/666666 [00:23<00:32, 11767.05it/s]\u001b[A\n",
            " 43%|████▎     | 287291/666666 [00:23<00:32, 11848.55it/s]\u001b[A\n",
            " 43%|████▎     | 288514/666666 [00:23<00:31, 11959.84it/s]\u001b[A\n",
            " 43%|████▎     | 289779/666666 [00:23<00:31, 12156.91it/s]\u001b[A\n",
            " 44%|████▎     | 291081/666666 [00:24<00:30, 12402.91it/s]\u001b[A\n",
            " 44%|████▍     | 292325/666666 [00:24<00:30, 12322.93it/s]\u001b[A\n",
            " 44%|████▍     | 293560/666666 [00:24<00:30, 12255.88it/s]\u001b[A\n",
            " 44%|████▍     | 294788/666666 [00:24<00:30, 12230.24it/s]\u001b[A\n",
            " 44%|████▍     | 296019/666666 [00:24<00:30, 12253.67it/s]\u001b[A\n",
            " 45%|████▍     | 297246/666666 [00:24<00:30, 12173.47it/s]\u001b[A\n",
            " 45%|████▍     | 298465/666666 [00:24<00:31, 11542.03it/s]\u001b[A\n",
            " 45%|████▍     | 299643/666666 [00:24<00:31, 11610.13it/s]\u001b[A\n",
            " 45%|████▌     | 300925/666666 [00:24<00:30, 11946.30it/s]\u001b[A\n",
            " 45%|████▌     | 302208/666666 [00:24<00:29, 12196.74it/s]\u001b[A\n",
            " 46%|████▌     | 303434/666666 [00:25<00:29, 12127.49it/s]\u001b[A\n",
            " 46%|████▌     | 304651/666666 [00:25<00:30, 12016.40it/s]\u001b[A\n",
            " 46%|████▌     | 305856/666666 [00:25<00:31, 11518.00it/s]\u001b[A\n",
            " 46%|████▌     | 307103/666666 [00:25<00:30, 11786.59it/s]\u001b[A\n",
            " 46%|████▌     | 308311/666666 [00:25<00:30, 11869.28it/s]\u001b[A\n",
            " 46%|████▋     | 309503/666666 [00:25<00:30, 11811.94it/s]\u001b[A\n",
            " 47%|████▋     | 310688/666666 [00:25<00:30, 11548.57it/s]\u001b[A\n",
            " 47%|████▋     | 311939/666666 [00:25<00:30, 11819.55it/s]\u001b[A\n",
            " 47%|████▋     | 313200/666666 [00:25<00:29, 12044.13it/s]\u001b[A\n",
            " 47%|████▋     | 314435/666666 [00:25<00:29, 12133.26it/s]\u001b[A\n",
            " 47%|████▋     | 315652/666666 [00:26<00:29, 12020.12it/s]\u001b[A\n",
            " 48%|████▊     | 316920/666666 [00:26<00:28, 12210.27it/s]\u001b[A\n",
            " 48%|████▊     | 318144/666666 [00:26<00:28, 12143.90it/s]\u001b[A\n",
            " 48%|████▊     | 319361/666666 [00:26<00:30, 11527.04it/s]\u001b[A\n",
            " 48%|████▊     | 320591/666666 [00:26<00:29, 11748.46it/s]\u001b[A\n",
            " 48%|████▊     | 321888/666666 [00:26<00:28, 12088.53it/s]\u001b[A\n",
            " 48%|████▊     | 323104/666666 [00:26<00:28, 11861.03it/s]\u001b[A\n",
            " 49%|████▊     | 324315/666666 [00:26<00:28, 11933.33it/s]\u001b[A\n",
            " 49%|████▉     | 325579/666666 [00:26<00:28, 12134.86it/s]\u001b[A\n",
            " 49%|████▉     | 326864/666666 [00:27<00:27, 12338.97it/s]\u001b[A\n",
            " 49%|████▉     | 328113/666666 [00:27<00:27, 12383.82it/s]\u001b[A\n",
            " 49%|████▉     | 329354/666666 [00:27<00:27, 12267.35it/s]\u001b[A\n",
            " 50%|████▉     | 330583/666666 [00:27<00:27, 12092.04it/s]\u001b[A\n",
            " 50%|████▉     | 331870/666666 [00:27<00:27, 12314.24it/s]\u001b[A\n",
            " 50%|████▉     | 333111/666666 [00:27<00:27, 12340.69it/s]\u001b[A\n",
            " 50%|█████     | 334347/666666 [00:27<00:27, 12245.20it/s]\u001b[A\n",
            " 50%|█████     | 335573/666666 [00:27<00:28, 11699.08it/s]\u001b[A\n",
            " 51%|█████     | 336825/666666 [00:27<00:27, 11932.07it/s]\u001b[A\n",
            " 51%|█████     | 338062/666666 [00:27<00:27, 12058.78it/s]\u001b[A\n",
            " 51%|█████     | 339287/666666 [00:28<00:27, 12113.68it/s]\u001b[A\n",
            " 51%|█████     | 340502/666666 [00:28<00:27, 12009.84it/s]\u001b[A\n",
            " 51%|█████▏    | 341710/666666 [00:28<00:27, 12028.00it/s]\u001b[A\n",
            " 51%|█████▏    | 342915/666666 [00:28<00:27, 11777.62it/s]\u001b[A\n",
            " 52%|█████▏    | 344102/666666 [00:28<00:27, 11803.62it/s]\u001b[A\n",
            " 52%|█████▏    | 345284/666666 [00:28<00:27, 11723.52it/s]\u001b[A\n",
            " 52%|█████▏    | 346458/666666 [00:28<00:27, 11560.35it/s]\u001b[A\n",
            " 52%|█████▏    | 347616/666666 [00:28<00:28, 11084.23it/s]\u001b[A\n",
            " 52%|█████▏    | 348730/666666 [00:28<00:28, 11075.07it/s]\u001b[A\n",
            " 52%|█████▏    | 349913/666666 [00:28<00:28, 11290.33it/s]\u001b[A\n",
            " 53%|█████▎    | 351130/666666 [00:29<00:27, 11539.37it/s]\u001b[A\n",
            " 53%|█████▎    | 352320/666666 [00:29<00:26, 11644.56it/s]\u001b[A\n",
            " 53%|█████▎    | 353488/666666 [00:29<00:27, 11580.09it/s]\u001b[A\n",
            " 53%|█████▎    | 354649/666666 [00:29<00:27, 11544.88it/s]\u001b[A\n",
            " 53%|█████▎    | 355853/666666 [00:29<00:26, 11688.34it/s]\u001b[A\n",
            " 54%|█████▎    | 357024/666666 [00:29<00:26, 11670.14it/s]\u001b[A\n",
            " 54%|█████▎    | 358221/666666 [00:29<00:26, 11755.65it/s]\u001b[A\n",
            " 54%|█████▍    | 359398/666666 [00:29<00:26, 11600.69it/s]\u001b[A\n",
            " 54%|█████▍    | 360646/666666 [00:29<00:25, 11850.79it/s]\u001b[A\n",
            " 54%|█████▍    | 361862/666666 [00:29<00:25, 11939.89it/s]\u001b[A\n",
            " 54%|█████▍    | 363078/666666 [00:30<00:25, 12004.47it/s]\u001b[A\n",
            " 55%|█████▍    | 364304/666666 [00:30<00:25, 12078.11it/s]\u001b[A\n",
            " 55%|█████▍    | 365520/666666 [00:30<00:24, 12098.95it/s]\u001b[A\n",
            " 55%|█████▌    | 366731/666666 [00:30<00:25, 11830.56it/s]\u001b[A\n",
            " 55%|█████▌    | 367916/666666 [00:30<00:25, 11790.70it/s]\u001b[A\n",
            " 55%|█████▌    | 369172/666666 [00:30<00:24, 12010.40it/s]\u001b[A\n",
            " 56%|█████▌    | 370401/666666 [00:30<00:24, 12092.34it/s]\u001b[A\n",
            " 56%|█████▌    | 371612/666666 [00:30<00:24, 11841.75it/s]\u001b[A\n",
            " 56%|█████▌    | 372826/666666 [00:30<00:24, 11926.51it/s]\u001b[A\n",
            " 56%|█████▌    | 374124/666666 [00:31<00:23, 12222.33it/s]\u001b[A\n",
            " 56%|█████▋    | 375418/666666 [00:31<00:23, 12427.71it/s]\u001b[A\n",
            " 56%|█████▋    | 376664/666666 [00:31<00:23, 12414.07it/s]\u001b[A\n",
            " 57%|█████▋    | 377908/666666 [00:31<00:23, 12351.85it/s]\u001b[A\n",
            " 57%|█████▋    | 379145/666666 [00:31<00:23, 12346.60it/s]\u001b[A\n",
            " 57%|█████▋    | 380430/666666 [00:31<00:22, 12492.05it/s]\u001b[A\n",
            " 57%|█████▋    | 381681/666666 [00:31<00:23, 12369.87it/s]\u001b[A\n",
            " 57%|█████▋    | 382920/666666 [00:31<00:22, 12352.51it/s]\u001b[A\n",
            " 58%|█████▊    | 384157/666666 [00:31<00:23, 11781.74it/s]\u001b[A\n",
            " 58%|█████▊    | 385370/666666 [00:31<00:23, 11883.98it/s]\u001b[A\n",
            " 58%|█████▊    | 386618/666666 [00:32<00:23, 12054.46it/s]\u001b[A\n",
            " 58%|█████▊    | 387828/666666 [00:32<00:23, 11953.20it/s]\u001b[A\n",
            " 58%|█████▊    | 389089/666666 [00:32<00:22, 12140.73it/s]\u001b[A\n",
            " 59%|█████▊    | 390306/666666 [00:32<00:22, 12143.98it/s]\u001b[A\n",
            " 59%|█████▊    | 391523/666666 [00:32<00:22, 11969.31it/s]\u001b[A\n",
            " 59%|█████▉    | 392755/666666 [00:32<00:22, 12071.27it/s]\u001b[A\n",
            " 59%|█████▉    | 393964/666666 [00:32<00:22, 11870.24it/s]\u001b[A\n",
            " 59%|█████▉    | 395153/666666 [00:32<00:23, 11683.81it/s]\u001b[A\n",
            " 59%|█████▉    | 396324/666666 [00:32<00:24, 11046.36it/s]\u001b[A\n",
            " 60%|█████▉    | 397494/666666 [00:32<00:23, 11233.42it/s]\u001b[A\n",
            " 60%|█████▉    | 398681/666666 [00:33<00:23, 11416.88it/s]\u001b[A\n",
            " 60%|█████▉    | 399865/666666 [00:33<00:23, 11540.36it/s]\u001b[A\n",
            " 60%|██████    | 401024/666666 [00:33<00:23, 11526.59it/s]\u001b[A\n",
            " 60%|██████    | 402180/666666 [00:33<00:22, 11499.89it/s]\u001b[A\n",
            " 61%|██████    | 403333/666666 [00:33<00:23, 11420.34it/s]\u001b[A\n",
            " 61%|██████    | 404555/666666 [00:33<00:22, 11647.07it/s]\u001b[A\n",
            " 61%|██████    | 405753/666666 [00:33<00:22, 11743.43it/s]\u001b[A\n",
            " 61%|██████    | 406930/666666 [00:33<00:22, 11709.50it/s]\u001b[A\n",
            " 61%|██████    | 408103/666666 [00:33<00:23, 11140.95it/s]\u001b[A\n",
            " 61%|██████▏   | 409344/666666 [00:33<00:22, 11493.20it/s]\u001b[A\n",
            " 62%|██████▏   | 410592/666666 [00:34<00:21, 11770.03it/s]\u001b[A\n",
            " 62%|██████▏   | 411839/666666 [00:34<00:21, 11969.65it/s]\u001b[A\n",
            " 62%|██████▏   | 413042/666666 [00:34<00:21, 11910.25it/s]\u001b[A\n",
            " 62%|██████▏   | 414313/666666 [00:34<00:20, 12137.06it/s]\u001b[A\n",
            " 62%|██████▏   | 415531/666666 [00:34<00:21, 11891.00it/s]\u001b[A\n",
            " 63%|██████▎   | 416826/666666 [00:34<00:20, 12188.33it/s]\u001b[A\n",
            " 63%|██████▎   | 418088/666666 [00:34<00:20, 12314.04it/s]\u001b[A\n",
            " 63%|██████▎   | 419323/666666 [00:34<00:20, 11920.36it/s]\u001b[A\n",
            " 63%|██████▎   | 420521/666666 [00:34<00:21, 11420.54it/s]\u001b[A\n",
            " 63%|██████▎   | 421756/666666 [00:35<00:20, 11682.39it/s]\u001b[A\n",
            " 63%|██████▎   | 422979/666666 [00:35<00:20, 11840.84it/s]\u001b[A\n",
            " 64%|██████▎   | 424183/666666 [00:35<00:20, 11898.95it/s]\u001b[A\n",
            " 64%|██████▍   | 425377/666666 [00:35<00:20, 11696.55it/s]\u001b[A\n",
            " 64%|██████▍   | 426622/666666 [00:35<00:20, 11911.13it/s]\u001b[A\n",
            " 64%|██████▍   | 427894/666666 [00:35<00:19, 12141.03it/s]\u001b[A\n",
            " 64%|██████▍   | 429112/666666 [00:35<00:19, 11981.00it/s]\u001b[A\n",
            " 65%|██████▍   | 430314/666666 [00:35<00:21, 11148.39it/s]\u001b[A\n",
            " 65%|██████▍   | 431528/666666 [00:35<00:20, 11426.94it/s]\u001b[A\n",
            " 65%|██████▍   | 432682/666666 [00:35<00:20, 11194.36it/s]\u001b[A\n",
            " 65%|██████▌   | 433811/666666 [00:36<00:20, 11189.04it/s]\u001b[A\n",
            " 65%|██████▌   | 435069/666666 [00:36<00:20, 11572.80it/s]\u001b[A\n",
            " 65%|██████▌   | 436285/666666 [00:36<00:19, 11740.03it/s]\u001b[A\n",
            " 66%|██████▌   | 437536/666666 [00:36<00:19, 11960.06it/s]\u001b[A\n",
            " 66%|██████▌   | 438747/666666 [00:36<00:18, 12002.86it/s]\u001b[A\n",
            " 66%|██████▌   | 439997/666666 [00:36<00:18, 12144.96it/s]\u001b[A\n",
            " 66%|██████▌   | 441276/666666 [00:36<00:18, 12330.57it/s]\u001b[A\n",
            " 66%|██████▋   | 442554/666666 [00:36<00:17, 12460.71it/s]\u001b[A\n",
            " 67%|██████▋   | 443803/666666 [00:36<00:18, 12224.04it/s]\u001b[A\n",
            " 67%|██████▋   | 445028/666666 [00:36<00:18, 11814.75it/s]\u001b[A\n",
            " 67%|██████▋   | 446247/666666 [00:37<00:18, 11922.49it/s]\u001b[A\n",
            " 67%|██████▋   | 447443/666666 [00:37<00:18, 11815.89it/s]\u001b[A\n",
            " 67%|██████▋   | 448628/666666 [00:37<00:18, 11599.67it/s]\u001b[A\n",
            " 67%|██████▋   | 449839/666666 [00:37<00:18, 11746.76it/s]\u001b[A\n",
            " 68%|██████▊   | 451109/666666 [00:37<00:17, 12014.62it/s]\u001b[A\n",
            " 68%|██████▊   | 452328/666666 [00:37<00:17, 12066.69it/s]\u001b[A\n",
            " 68%|██████▊   | 453553/666666 [00:37<00:17, 12118.47it/s]\u001b[A\n",
            " 68%|██████▊   | 454810/666666 [00:37<00:17, 12248.72it/s]\u001b[A\n",
            " 68%|██████▊   | 456078/666666 [00:37<00:17, 12374.34it/s]\u001b[A\n",
            " 69%|██████▊   | 457317/666666 [00:38<00:17, 11973.34it/s]\u001b[A\n",
            " 69%|██████▉   | 458519/666666 [00:38<00:17, 11856.36it/s]\u001b[A\n",
            " 69%|██████▉   | 459790/666666 [00:38<00:17, 12096.95it/s]\u001b[A\n",
            " 69%|██████▉   | 461028/666666 [00:38<00:16, 12179.45it/s]\u001b[A\n",
            " 69%|██████▉   | 462249/666666 [00:38<00:17, 11979.07it/s]\u001b[A\n",
            " 70%|██████▉   | 463450/666666 [00:38<00:17, 11767.88it/s]\u001b[A\n",
            " 70%|██████▉   | 464630/666666 [00:38<00:17, 11709.20it/s]\u001b[A\n",
            " 70%|██████▉   | 465857/666666 [00:38<00:16, 11869.38it/s]\u001b[A\n",
            " 70%|███████   | 467104/666666 [00:38<00:16, 12042.05it/s]\u001b[A\n",
            " 70%|███████   | 468313/666666 [00:38<00:16, 12054.76it/s]\u001b[A\n",
            " 70%|███████   | 469520/666666 [00:39<00:16, 11670.25it/s]\u001b[A\n",
            " 71%|███████   | 470731/666666 [00:39<00:16, 11796.63it/s]\u001b[A\n",
            " 71%|███████   | 471941/666666 [00:39<00:16, 11884.39it/s]\u001b[A\n",
            " 71%|███████   | 473137/666666 [00:39<00:16, 11904.07it/s]\u001b[A\n",
            " 71%|███████   | 474374/666666 [00:39<00:15, 12037.75it/s]\u001b[A\n",
            " 71%|███████▏  | 475639/666666 [00:39<00:15, 12211.80it/s]\u001b[A\n",
            " 72%|███████▏  | 476919/666666 [00:39<00:15, 12381.22it/s]\u001b[A\n",
            " 72%|███████▏  | 478159/666666 [00:39<00:15, 12320.22it/s]\u001b[A\n",
            " 72%|███████▏  | 479393/666666 [00:39<00:15, 12065.76it/s]\u001b[A\n",
            " 72%|███████▏  | 480625/666666 [00:39<00:15, 12139.53it/s]\u001b[A\n",
            " 72%|███████▏  | 481841/666666 [00:40<00:15, 11574.93it/s]\u001b[A\n",
            " 72%|███████▏  | 483006/666666 [00:40<00:15, 11558.23it/s]\u001b[A\n",
            " 73%|███████▎  | 484224/666666 [00:40<00:15, 11737.07it/s]\u001b[A\n",
            " 73%|███████▎  | 485467/666666 [00:40<00:15, 11935.53it/s]\u001b[A\n",
            " 73%|███████▎  | 486715/666666 [00:40<00:14, 12091.33it/s]\u001b[A\n",
            " 73%|███████▎  | 487961/666666 [00:40<00:14, 12197.09it/s]\u001b[A\n",
            " 73%|███████▎  | 489184/666666 [00:40<00:14, 11975.28it/s]\u001b[A\n",
            " 74%|███████▎  | 490398/666666 [00:40<00:14, 12023.21it/s]\u001b[A\n",
            " 74%|███████▎  | 491657/666666 [00:40<00:14, 12187.49it/s]\u001b[A\n",
            " 74%|███████▍  | 492878/666666 [00:40<00:14, 11992.45it/s]\u001b[A\n",
            " 74%|███████▍  | 494080/666666 [00:41<00:15, 11501.23it/s]\u001b[A\n",
            " 74%|███████▍  | 495304/666666 [00:41<00:14, 11710.61it/s]\u001b[A\n",
            " 74%|███████▍  | 496522/666666 [00:41<00:14, 11847.07it/s]\u001b[A\n",
            " 75%|███████▍  | 497752/666666 [00:41<00:14, 11978.11it/s]\u001b[A\n",
            " 75%|███████▍  | 498953/666666 [00:41<00:14, 11951.92it/s]\u001b[A\n",
            " 75%|███████▌  | 500187/666666 [00:41<00:13, 12065.32it/s]\u001b[A\n",
            " 75%|███████▌  | 501396/666666 [00:41<00:13, 12000.23it/s]\u001b[A\n",
            " 75%|███████▌  | 502671/666666 [00:41<00:13, 12214.63it/s]\u001b[A\n",
            " 76%|███████▌  | 503895/666666 [00:41<00:13, 12162.39it/s]\u001b[A\n",
            " 76%|███████▌  | 505130/666666 [00:42<00:13, 12216.39it/s]\u001b[A\n",
            " 76%|███████▌  | 506353/666666 [00:42<00:13, 11836.76it/s]\u001b[A\n",
            " 76%|███████▌  | 507614/666666 [00:42<00:13, 12057.51it/s]\u001b[A\n",
            " 76%|███████▋  | 508824/666666 [00:42<00:13, 11962.30it/s]\u001b[A\n",
            " 77%|███████▋  | 510023/666666 [00:42<00:13, 11639.23it/s]\u001b[A\n",
            " 77%|███████▋  | 511191/666666 [00:42<00:13, 11580.61it/s]\u001b[A\n",
            " 77%|███████▋  | 512414/666666 [00:42<00:13, 11763.56it/s]\u001b[A\n",
            " 77%|███████▋  | 513643/666666 [00:42<00:12, 11914.53it/s]\u001b[A\n",
            " 77%|███████▋  | 514853/666666 [00:42<00:12, 11968.73it/s]\u001b[A\n",
            " 77%|███████▋  | 516062/666666 [00:42<00:12, 12002.49it/s]\u001b[A\n",
            " 78%|███████▊  | 517328/666666 [00:43<00:12, 12191.48it/s]\u001b[A\n",
            " 78%|███████▊  | 518549/666666 [00:43<00:12, 11854.94it/s]\u001b[A\n",
            " 78%|███████▊  | 519738/666666 [00:43<00:12, 11786.76it/s]\u001b[A\n",
            " 78%|███████▊  | 520952/666666 [00:43<00:12, 11888.68it/s]\u001b[A\n",
            " 78%|███████▊  | 522218/666666 [00:43<00:11, 12107.73it/s]\u001b[A\n",
            " 79%|███████▊  | 523488/666666 [00:43<00:11, 12277.95it/s]\u001b[A\n",
            " 79%|███████▊  | 524718/666666 [00:43<00:11, 12196.86it/s]\u001b[A\n",
            " 79%|███████▉  | 525940/666666 [00:43<00:11, 12184.94it/s]\u001b[A\n",
            " 79%|███████▉  | 527160/666666 [00:43<00:11, 12154.45it/s]\u001b[A\n",
            " 79%|███████▉  | 528395/666666 [00:43<00:11, 12211.60it/s]\u001b[A\n",
            " 79%|███████▉  | 529617/666666 [00:44<00:11, 12195.33it/s]\u001b[A\n",
            " 80%|███████▉  | 530837/666666 [00:44<00:11, 11779.93it/s]\u001b[A\n",
            " 80%|███████▉  | 532042/666666 [00:44<00:11, 11859.44it/s]\u001b[A\n",
            " 80%|███████▉  | 533311/666666 [00:44<00:11, 12093.60it/s]\u001b[A\n",
            " 80%|████████  | 534544/666666 [00:44<00:10, 12161.68it/s]\u001b[A\n",
            " 80%|████████  | 535763/666666 [00:44<00:10, 11997.59it/s]\u001b[A\n",
            " 81%|████████  | 536992/666666 [00:44<00:10, 12082.49it/s]\u001b[A\n",
            " 81%|████████  | 538233/666666 [00:44<00:10, 12176.43it/s]\u001b[A\n",
            " 81%|████████  | 539503/666666 [00:44<00:10, 12326.13it/s]\u001b[A\n",
            " 81%|████████  | 540737/666666 [00:44<00:10, 12199.54it/s]\u001b[A\n",
            " 81%|████████▏ | 542012/666666 [00:45<00:10, 12359.49it/s]\u001b[A\n",
            " 81%|████████▏ | 543250/666666 [00:45<00:10, 11681.38it/s]\u001b[A\n",
            " 82%|████████▏ | 544470/666666 [00:45<00:10, 11831.39it/s]\u001b[A\n",
            " 82%|████████▏ | 545660/666666 [00:45<00:10, 11800.69it/s]\u001b[A\n",
            " 82%|████████▏ | 546845/666666 [00:45<00:10, 11596.68it/s]\u001b[A\n",
            " 82%|████████▏ | 548009/666666 [00:45<00:10, 11568.23it/s]\u001b[A\n",
            " 82%|████████▏ | 549258/666666 [00:45<00:09, 11828.35it/s]\u001b[A\n",
            " 83%|████████▎ | 550535/666666 [00:45<00:09, 12095.63it/s]\u001b[A\n",
            " 83%|████████▎ | 551749/666666 [00:45<00:09, 12042.84it/s]\u001b[A\n",
            " 83%|████████▎ | 553006/666666 [00:45<00:09, 12195.92it/s]\u001b[A\n",
            " 83%|████████▎ | 554244/666666 [00:46<00:09, 12250.16it/s]\u001b[A\n",
            " 83%|████████▎ | 555471/666666 [00:46<00:09, 11972.53it/s]\u001b[A\n",
            " 84%|████████▎ | 556671/666666 [00:46<00:09, 11363.36it/s]\u001b[A\n",
            " 84%|████████▎ | 557816/666666 [00:46<00:09, 11358.64it/s]\u001b[A\n",
            " 84%|████████▍ | 559033/666666 [00:46<00:09, 11588.33it/s]\u001b[A\n",
            " 84%|████████▍ | 560199/666666 [00:46<00:09, 11606.95it/s]\u001b[A\n",
            " 84%|████████▍ | 561475/666666 [00:46<00:08, 11929.59it/s]\u001b[A\n",
            " 84%|████████▍ | 562739/666666 [00:46<00:08, 12132.81it/s]\u001b[A\n",
            " 85%|████████▍ | 563957/666666 [00:46<00:08, 12129.30it/s]\u001b[A\n",
            " 85%|████████▍ | 565230/666666 [00:47<00:08, 12300.10it/s]\u001b[A\n",
            " 85%|████████▍ | 566524/666666 [00:47<00:08, 12484.74it/s]\u001b[A\n",
            " 85%|████████▌ | 567775/666666 [00:47<00:08, 12049.89it/s]\u001b[A\n",
            " 85%|████████▌ | 568986/666666 [00:47<00:08, 12066.62it/s]\u001b[A\n",
            " 86%|████████▌ | 570223/666666 [00:47<00:07, 12154.52it/s]\u001b[A\n",
            " 86%|████████▌ | 571449/666666 [00:47<00:07, 12185.12it/s]\u001b[A\n",
            " 86%|████████▌ | 572684/666666 [00:47<00:07, 12231.49it/s]\u001b[A\n",
            " 86%|████████▌ | 573928/666666 [00:47<00:07, 12291.77it/s]\u001b[A\n",
            " 86%|████████▋ | 575169/666666 [00:47<00:07, 12326.88it/s]\u001b[A\n",
            " 86%|████████▋ | 576433/666666 [00:47<00:07, 12417.89it/s]\u001b[A\n",
            " 87%|████████▋ | 577720/666666 [00:48<00:07, 12549.15it/s]\u001b[A\n",
            " 87%|████████▋ | 578976/666666 [00:48<00:07, 12494.96it/s]\u001b[A\n",
            " 87%|████████▋ | 580227/666666 [00:48<00:07, 11984.87it/s]\u001b[A\n",
            " 87%|████████▋ | 581477/666666 [00:48<00:07, 12133.67it/s]\u001b[A\n",
            " 87%|████████▋ | 582714/666666 [00:48<00:06, 12203.25it/s]\u001b[A\n",
            " 88%|████████▊ | 583938/666666 [00:48<00:06, 12197.70it/s]\u001b[A\n",
            " 88%|████████▊ | 585160/666666 [00:48<00:06, 12124.60it/s]\u001b[A\n",
            " 88%|████████▊ | 586388/666666 [00:48<00:06, 12169.28it/s]\u001b[A\n",
            " 88%|████████▊ | 587676/666666 [00:48<00:06, 12373.84it/s]\u001b[A\n",
            " 88%|████████▊ | 588915/666666 [00:48<00:06, 12153.40it/s]\u001b[A\n",
            " 89%|████████▊ | 590170/666666 [00:49<00:06, 12269.27it/s]\u001b[A\n",
            " 89%|████████▊ | 591425/666666 [00:49<00:06, 12350.10it/s]\u001b[A\n",
            " 89%|████████▉ | 592662/666666 [00:49<00:06, 11966.88it/s]\u001b[A\n",
            " 89%|████████▉ | 593922/666666 [00:49<00:05, 12149.90it/s]\u001b[A\n",
            " 89%|████████▉ | 595178/666666 [00:49<00:05, 12268.51it/s]\u001b[A\n",
            " 89%|████████▉ | 596408/666666 [00:49<00:05, 12084.33it/s]\u001b[A\n",
            " 90%|████████▉ | 597619/666666 [00:49<00:05, 11944.61it/s]\u001b[A\n",
            " 90%|████████▉ | 598852/666666 [00:49<00:05, 12055.42it/s]\u001b[A\n",
            " 90%|█████████ | 600147/666666 [00:49<00:05, 12309.70it/s]\u001b[A\n",
            " 90%|█████████ | 601381/666666 [00:49<00:05, 12217.71it/s]\u001b[A\n",
            " 90%|█████████ | 602605/666666 [00:50<00:05, 12046.61it/s]\u001b[A\n",
            " 91%|█████████ | 603812/666666 [00:50<00:05, 11875.61it/s]\u001b[A\n",
            " 91%|█████████ | 605002/666666 [00:50<00:05, 11575.90it/s]\u001b[A\n",
            " 91%|█████████ | 606252/666666 [00:50<00:05, 11836.65it/s]\u001b[A\n",
            " 91%|█████████ | 607538/666666 [00:50<00:04, 12125.90it/s]\u001b[A\n",
            " 91%|█████████▏| 608798/666666 [00:50<00:04, 12261.25it/s]\u001b[A\n",
            " 92%|█████████▏| 610036/666666 [00:50<00:04, 12294.18it/s]\u001b[A\n",
            " 92%|█████████▏| 611308/666666 [00:50<00:04, 12416.58it/s]\u001b[A\n",
            " 92%|█████████▏| 612552/666666 [00:50<00:04, 12263.38it/s]\u001b[A\n",
            " 92%|█████████▏| 613781/666666 [00:51<00:04, 12172.11it/s]\u001b[A\n",
            " 92%|█████████▏| 615044/666666 [00:51<00:04, 12305.74it/s]\u001b[A\n",
            " 92%|█████████▏| 616315/666666 [00:51<00:04, 12422.24it/s]\u001b[A\n",
            " 93%|█████████▎| 617559/666666 [00:51<00:04, 12093.48it/s]\u001b[A\n",
            " 93%|█████████▎| 618818/666666 [00:51<00:03, 12236.67it/s]\u001b[A\n",
            " 93%|█████████▎| 620107/666666 [00:51<00:03, 12424.11it/s]\u001b[A\n",
            " 93%|█████████▎| 621399/666666 [00:51<00:03, 12566.86it/s]\u001b[A\n",
            " 93%|█████████▎| 622658/666666 [00:51<00:03, 12299.57it/s]\u001b[A\n",
            " 94%|█████████▎| 623891/666666 [00:51<00:03, 11672.92it/s]\u001b[A\n",
            " 94%|█████████▍| 625067/666666 [00:51<00:03, 11585.36it/s]\u001b[A\n",
            " 94%|█████████▍| 626277/666666 [00:52<00:03, 11734.71it/s]\u001b[A\n",
            " 94%|█████████▍| 627494/666666 [00:52<00:03, 11860.21it/s]\u001b[A\n",
            " 94%|█████████▍| 628754/666666 [00:52<00:03, 12071.59it/s]\u001b[A\n",
            " 94%|█████████▍| 629965/666666 [00:52<00:03, 11799.11it/s]\u001b[A\n",
            " 95%|█████████▍| 631215/666666 [00:52<00:02, 11997.89it/s]\u001b[A\n",
            " 95%|█████████▍| 632491/666666 [00:52<00:02, 12215.42it/s]\u001b[A\n",
            " 95%|█████████▌| 633716/666666 [00:52<00:02, 12151.13it/s]\u001b[A\n",
            " 95%|█████████▌| 634934/666666 [00:52<00:02, 12094.10it/s]\u001b[A\n",
            " 95%|█████████▌| 636146/666666 [00:52<00:02, 11998.99it/s]\u001b[A\n",
            " 96%|█████████▌| 637348/666666 [00:52<00:02, 11984.32it/s]\u001b[A\n",
            " 96%|█████████▌| 638599/666666 [00:53<00:02, 12136.36it/s]\u001b[A\n",
            " 96%|█████████▌| 639884/666666 [00:53<00:02, 12340.57it/s]\u001b[A\n",
            " 96%|█████████▌| 641147/666666 [00:53<00:02, 12425.84it/s]\u001b[A\n",
            " 96%|█████████▋| 642391/666666 [00:53<00:02, 11703.91it/s]\u001b[A\n",
            " 97%|█████████▋| 643592/666666 [00:53<00:01, 11793.79it/s]\u001b[A\n",
            " 97%|█████████▋| 644845/666666 [00:53<00:01, 12000.41it/s]\u001b[A\n",
            " 97%|█████████▋| 646113/666666 [00:53<00:01, 12195.10it/s]\u001b[A\n",
            " 97%|█████████▋| 647338/666666 [00:53<00:01, 11974.26it/s]\u001b[A\n",
            " 97%|█████████▋| 648551/666666 [00:53<00:01, 12018.68it/s]\u001b[A\n",
            " 97%|█████████▋| 649812/666666 [00:53<00:01, 12189.60it/s]\u001b[A\n",
            " 98%|█████████▊| 651064/666666 [00:54<00:01, 12286.16it/s]\u001b[A\n",
            " 98%|█████████▊| 652295/666666 [00:54<00:01, 11996.22it/s]\u001b[A\n",
            " 98%|█████████▊| 653498/666666 [00:54<00:01, 11970.40it/s]\u001b[A\n",
            " 98%|█████████▊| 654698/666666 [00:54<00:01, 11826.53it/s]\u001b[A\n",
            " 98%|█████████▊| 655953/666666 [00:54<00:00, 12033.29it/s]\u001b[A\n",
            " 99%|█████████▊| 657232/666666 [00:54<00:00, 12248.35it/s]\u001b[A\n",
            " 99%|█████████▉| 658460/666666 [00:54<00:00, 12184.36it/s]\u001b[A\n",
            " 99%|█████████▉| 659681/666666 [00:54<00:00, 12181.62it/s]\u001b[A\n",
            " 99%|█████████▉| 660942/666666 [00:54<00:00, 12306.83it/s]\u001b[A\n",
            " 99%|█████████▉| 662174/666666 [00:55<00:00, 12229.01it/s]\u001b[A\n",
            "100%|█████████▉| 663398/666666 [00:55<00:00, 12214.34it/s]\u001b[A\n",
            "100%|█████████▉| 664621/666666 [00:55<00:00, 12101.75it/s]\u001b[A\n",
            "100%|█████████▉| 665837/666666 [00:55<00:00, 12118.47it/s]\u001b[A\n",
            "100%|██████████| 666666/666666 [00:55<00:00, 12035.35it/s]\u001b[A"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "CCtnGCim630U",
        "colab_type": "code",
        "outputId": "3ca0b49d-4820-4f28-d582-762dbc2c3a85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "word2index = {'PAD': 0}\n",
        "vectors = []\n",
        "    \n",
        "word2vec_file = open('gdrive/My Drive/CompLing/cc.ru.300.vec')\n",
        "    \n",
        "n_words, embedding_dim = word2vec_file.readline().split()\n",
        "n_words, embedding_dim = int(n_words), int(embedding_dim)\n",
        "\n",
        "# Zero vector for PAD\n",
        "vectors.append(np.zeros((1, embedding_dim)))\n",
        "\n",
        "progress_bar = tqdm(desc='Read word2vec', total=n_words)\n",
        "\n",
        "while True:\n",
        "\n",
        "    line = word2vec_file.readline().strip()\n",
        "\n",
        "    if not line:\n",
        "        break\n",
        "        \n",
        "    current_parts = line.split()\n",
        "    current_word = ' '.join(current_parts[:-embedding_dim])\n",
        "\n",
        "    if current_word in word2freq:\n",
        "        word2index[current_word] = len(word2index)\n",
        "        current_vectors = current_parts[-embedding_dim:]\n",
        "        current_vectors = np.array(list(map(float, current_vectors)))\n",
        "        current_vectors = np.expand_dims(current_vectors, 0)\n",
        "        vectors.append(current_vectors)\n",
        "\n",
        "    progress_bar.update(1)\n",
        "\n",
        "progress_bar.close()\n",
        "word2vec_file.close()\n",
        "vectors = np.concatenate(vectors)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Read word2vec: 100%|██████████| 2000000/2000000 [02:00<00:00, 16636.06it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "4scrjJmB630e",
        "colab_type": "code",
        "outputId": "b4b33a49-62d3-44e3-975c-7e41129f8a48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        }
      },
      "source": [
        "unk_words = [word for word in word2freq if word not in word2index]\n",
        "unk_counts = [word2freq[word] for word in unk_words]\n",
        "n_unk = sum(unk_counts) * 100 / sum(list(word2freq.values()))\n",
        "\n",
        "sub_sample_unk_words = {word: word2freq[word] for word in unk_words}\n",
        "sorted_unk_words = list(sorted(sub_sample_unk_words, key=lambda x: sub_sample_unk_words[x], reverse=True))\n",
        "\n",
        "print('Мы не знаем {:.2f} % слов в датасете'.format(n_unk))\n",
        "print('Количество неизвестных слов {} из {}, то есть {:.2f} % уникальных слов в словаре'.format(\n",
        "    len(unk_words), len(word2freq), len(unk_words) * 100 / len(word2freq)))\n",
        "print('В среднем каждое встречается {:.2f} раз'.format(np.mean(unk_counts)))\n",
        "print()\n",
        "print('Топ 5 невошедших слов:')\n",
        "\n",
        "for i in range(5):\n",
        "    print(sorted_unk_words[i], 'с количеством вхождениий -', word2freq[sorted_unk_words[i]])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Мы не знаем 1.94 % слов в датасете\n",
            "Количество неизвестных слов 106532 из 327438, то есть 32.54 % уникальных слов в словаре\n",
            "В среднем каждое встречается 1.37 раз\n",
            "\n",
            "Топ 5 невошедших слов:\n",
            "). с количеством вхождениий - 2038\n",
            "), с количеством вхождениий - 2027\n",
            ".) с количеством вхождениий - 756\n",
            "», с количеством вхождениий - 314\n",
            "*** с количеством вхождениий - 280\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "73hYovqp630o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class WordData(Dataset):\n",
        "    \n",
        "    def __init__(self, x_data, y_data, word2index, sequence_length=32, pad_token='PAD', verbose=True):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.x_data = []\n",
        "        self.y_data = []\n",
        "        self.b_data = []\n",
        "        \n",
        "        self.word2index = word2index\n",
        "        self.sequence_length = sequence_length\n",
        "        \n",
        "        self.pad_token = pad_token\n",
        "        self.pad_index = self.word2index[self.pad_token]\n",
        "        \n",
        "        self.load(x_data, y_data, verbose=verbose)\n",
        "        \n",
        "    @staticmethod\n",
        "    def process_text(text):\n",
        "        \n",
        "        # Место для вашей предобработки\n",
        "        words = smart_process_text(text)\n",
        "#         words = wordpunct_tokenize(text.lower())\n",
        "\n",
        "        return words\n",
        "        \n",
        "    def load(self, data, data2, verbose=True):\n",
        "        \n",
        "#         data_iterator = tqdm(data, desc='Loading data', disable=not verbose)\n",
        "        \n",
        "#         for text in data_iterator:\n",
        "#             words = self.process_text(text)\n",
        "#             indexed_words = self.indexing(words)\n",
        "#             print(indexed_words)\n",
        "#             self.x_data.append(indexed_words)\n",
        "        \n",
        "        data_iterator = tqdm(range(len(data)), desc='Loading data', disable=not verbose, position=0)\n",
        "\n",
        "#         for i in data_iterator:\n",
        "#             words = self.process_text(data[i])\n",
        "#             emb = get_embedding(' '.join(words))\n",
        "#             self.x_data.append(emb)\n",
        "#             self.y_data.append(data2[i])\n",
        "        \n",
        "        \n",
        "        for i in data_iterator:            \n",
        "            words = self.process_text(data[i])\n",
        "            indexed_words = self.indexing(words)\n",
        "            self.x_data.append(indexed_words)\n",
        "            self.y_data.append(data2[i])        \n",
        "            \n",
        "    \n",
        "    def indexing(self, tokenized_text):\n",
        "\n",
        "        # здесь мы не используем токен UNK, потому что мы мы его специально не учили\n",
        "        # становится непонятно какой же эмбеддинг присвоить неизвестному слову,\n",
        "        # поэтому просто выбрасываем наши неизветсные слова\n",
        "        \n",
        "        ### CODE ###\n",
        "\n",
        "        return [self.word2index[token] if token in self.word2index else self.word2index[\"непонятно\"] for token in tokenized_text]\n",
        "    \n",
        "    def padding(self, sequence):\n",
        "        \n",
        "        # Ограничить длину self.sequence_length\n",
        "        # если длина меньше максимально - западить\n",
        "        \n",
        "        ### CODE ###\n",
        "\n",
        "        if len(sequence) > self.sequence_length:\n",
        "            sequence = sequence[:self.sequence_length]\n",
        "        elif len(sequence) < self.sequence_length:\n",
        "            sequence = sequence + [self.pad_index] * (self.sequence_length - len(sequence))\n",
        "\n",
        "        return sequence\n",
        "    \n",
        "    def __len__(self):\n",
        "        \n",
        "        return len(self.x_data)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        \n",
        "        x = self.x_data[idx]\n",
        "        x = self.padding(x)\n",
        "        x = torch.Tensor(x).long()\n",
        "        \n",
        "        y = self.y_data[idx]\n",
        "        \n",
        "        return x, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "lY0azEUK630w",
        "colab_type": "code",
        "outputId": "9f543954-2b84-4da6-fc09-31b6d0d5ac14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "x_train, x_validation, y_train, y_validation = train_test_split(train.question, train.main_category, test_size=0.1)\n",
        "\n",
        "train_dataset = WordData(list(x_train), list(y_train), word2index)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64)\n",
        "\n",
        "validation_dataset = WordData(list(x_validation), list(y_validation), word2index)\n",
        "validation_loader = DataLoader(validation_dataset, batch_size=64)\n",
        "\n",
        "test_dataset = WordData(list(test.question), np.zeros((test.shape[0])), word2index)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data: 100%|██████████| 599999/599999 [00:49<00:00, 12068.36it/s]\n",
            "Loading data: 100%|██████████| 66667/66667 [00:05<00:00, 12606.34it/s]\n",
            "Loading data: 100%|██████████| 200000/200000 [00:16<00:00, 11787.79it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Nqc9b04Y6307",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for x, y in test_loader:\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "cDmmVjNW631C",
        "colab_type": "code",
        "outputId": "70b143b4-a4ff-4f98-db3a-421e5bd133d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "x.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 32])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "wnEs-Jsa631K",
        "colab_type": "code",
        "outputId": "1ad9ff94-686b-4619-b6e3-9b92ed1a91cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Rctwued_631R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_classes = train.main_category.unique().shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Pr2WTzNO631Y",
        "colab_type": "code",
        "outputId": "5bf12c75-7385-45b4-ae40-c5317f5619d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# torch.cuda.empty_cache()\n",
        "print(\"CUDA RAM usage\", torch.cuda.max_memory_allocated(device))\n",
        "\n",
        "def tsort(ts):\n",
        "  z = torch.tensor([len(torch.nonzero(ts[i])) for i in range(ts.shape[0])]).sort(descending=True)\n",
        "  return ts[z[1]], z[0], np.argsort(z[1]).to(device)\n",
        "\n",
        "class DeepAverageNetwork(torch.nn.Module):\n",
        "    \n",
        "    def __init__(self, embedding_matrix, n_classes):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding_layer = torch.nn.Embedding.from_pretrained(torch.Tensor(embedding_matrix))\n",
        "        \n",
        "        self.l1 = torch.nn.Linear(300, 256)\n",
        "        self.lstm = torch.nn.LSTM(input_size=300,hidden_size=256*2,bidirectional=True, batch_first=True)\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.l2 = torch.nn.Linear(256, 128)\n",
        "        self.lout = torch.nn.Linear(128, n_classes)\n",
        "        \n",
        "        self.embedding_length = 300\n",
        "#         self.hidden_size = 64\n",
        "        self.hidden_size = 64\n",
        "        self.drop = nn.Dropout2d(0.25)    \n",
        "        \n",
        "        self.lstm = nn.LSTM(input_size=self.embedding_length,hidden_size=self.hidden_size,\\\n",
        "                        bidirectional=True, batch_first=True)\n",
        "        self.linear = nn.Linear(self.hidden_size*2, n_classes)   \n",
        "        \n",
        "#         self.linear_attn = nn.Linear(self.hidden_size, n_classes)   \n",
        "        self.linear_attn = nn.Linear(156, n_classes)   \n",
        "    \n",
        "        self.linear_cnn = nn.Linear(512, n_classes)   \n",
        "        \n",
        "        self.ak = nn.Linear(self.hidden_size*2, n_classes)\n",
        "        self.aq = nn.Linear(self.hidden_size*2, n_classes)\n",
        "        self.av = nn.Linear(self.hidden_size*2, n_classes)\n",
        "        \n",
        "        kerns = [2,4,6,8]\n",
        "        seqlen = 32\n",
        "        con_size = 64\n",
        "        con_out = 64 * 2\n",
        "        \n",
        "        self.conv1 = nn.Conv1d(in_channels=con_size, out_channels= con_out, kernel_size=kerns[0])\n",
        "        self.conv2 = nn.Conv1d(in_channels=con_size, out_channels= con_out, kernel_size=kerns[1])\n",
        "        self.conv3 = nn.Conv1d(in_channels=con_size, out_channels= con_out, kernel_size=kerns[2])\n",
        "        self.conv4 = nn.Conv1d(in_channels=con_size, out_channels= con_out, kernel_size=kerns[3])\n",
        "\n",
        "        self.mp1 = nn.MaxPool1d(kernel_size=(seqlen-kerns[0]+1))\n",
        "        self.mp2 = nn.MaxPool1d(kernel_size=(seqlen-kerns[1]+1))\n",
        "        self.mp3 = nn.MaxPool1d(kernel_size=(seqlen-kerns[2]+1))\n",
        "        self.mp4 = nn.MaxPool1d(kernel_size=(seqlen-kerns[3]+1))\n",
        "        self.relu = nn.ReLU()\n",
        "        \n",
        "        \n",
        "    def forward(self, x):\n",
        "#         print(\"in\", x.shape)\n",
        "        x_sorted, lens, unindex = tsort(x)\n",
        "        x = self.embedding_layer(x_sorted)\n",
        "#         print(\"with embs\", x.shape)\n",
        "        x = self.drop(x)\n",
        "        z = pack_padded_sequence(x, lens, batch_first=True)\n",
        "        x, _ =  self.lstm(z)                \n",
        "        x, _ = pad_packed_sequence(x, batch_first=True)        \n",
        "        x = x.index_select(0, unindex)\n",
        "#         print(\"packing out\", x.shape)\n",
        "        x = x.transpose(0, 1)\n",
        "#         print(\"transposed\", x.shape)\n",
        "        x = x[0]\n",
        "#         print(\"one dim\", x.shape)\n",
        "#         x_key = self.attn_key(x)\n",
        "#         x_que = self.attn_query(x)\n",
        "#         x_val = self.attn_val(x)\n",
        "        \n",
        "#         att_scores = torch.bmm(x_que, x_key.transpose(1, 2))\n",
        "#         print(att_scores.shape)\n",
        "#         att_scores_scaled = (att_scores) / math.sqrt(x_key.shape[-1])\n",
        "#         att_distribution = torch.nn.functional.softmax(att_scores_scaled, 2)\n",
        "#         att_vectors = torch.bmm(att_distribution, x_val)\n",
        "        lstm_out = x\n",
        "        out_key = self.ak(lstm_out)\n",
        "        out_query = self.aq(lstm_out)\n",
        "        out_value = self.av(lstm_out)\n",
        "        \n",
        "        ok2 = out_key.transpose(0, 1)\n",
        "        ov2 = out_value.transpose(0, 1)\n",
        "#         print(out_query.shape, out_key.shape, ok2.shape)\n",
        "        \n",
        "#         att_scores = torch.bmm(out_query, out_key.transpose(1, 2))\n",
        "        att_scores = torch.mm(out_query, ok2) \n",
        "#         print(att_scores.shape)\n",
        "        sq = math.sqrt(out_key.shape[-1])\n",
        "#         print(\"att_scores\", att_scores.shape)\n",
        "#         print(\"sq\",sq)\n",
        "        att_scores_scaled = (att_scores) / sq\n",
        "#         print(att_scores_scaled.shape)\n",
        "        \n",
        "        att_distribution = torch.nn.functional.softmax(att_scores_scaled, 1)\n",
        "#         print(att_distribution.shape)\n",
        "        att_vectors = torch.mm(att_distribution, out_value)\n",
        "#         print(\"vecs\", att_vectors.shape)\n",
        "        lstm_out_cnn = torch.cat([lstm_out, att_vectors], dim=-1)\n",
        "#         print(\"cat\", lstm_out_cnn.shape)\n",
        "#         print(x.shape)\n",
        "        x = lstm_out_cnn\n",
        "#         x = x.transpose(0, 1)        \n",
        "#         print(lstm_out_cnn.shape)\n",
        "        x = self.drop(x)\n",
        "        \n",
        "#         x_transposed = x.transpose(1, 2)  \n",
        "#         x_transposed = x.unsqueeze(0)\n",
        "# #         print(x_transposed.shape)\n",
        "#         x1 = F.relu(self.conv1(x_transposed))\n",
        "#         x2 = F.relu(self.conv2(x_transposed))\n",
        "#         x3 = F.relu(self.conv3(x_transposed))\n",
        "#         x4 = F.relu(self.conv4(x_transposed))          \n",
        "\n",
        "#         mp1x = self.mp1(x1)\n",
        "#         mp2x = self.mp2(x2)\n",
        "#         mp3x = self.mp3(x3)\n",
        "#         mp4x = self.mp4(x4)\n",
        "        \n",
        "#         x_cat = torch.cat((mp1x, mp2x, mp3x, mp4x), 1)\n",
        "                \n",
        "#         print(x_cat.shape)\n",
        "#         x = x_cat.squeeze(0)\n",
        "#         print(x.shape)\n",
        "#         x = x.transpose(0, 1)\n",
        "        \n",
        "#         print(x.shape)\n",
        "#         x = self.linear_cnn(x)\n",
        "    \n",
        "        x = self.linear_attn(x)\n",
        "        \n",
        "\n",
        "#         sequence_lengths = (x > 0).sum(dim=1)\n",
        "#         sequence_lengths[sequence_lengths == 0.] = 1       \n",
        "#         x = self.embedding_layer(x)\n",
        "#         x = x.mean(dim=-2)        \n",
        "#         lengths_scaling = sequence_lengths.float() / x.size(1)\n",
        "#         lengths_scaling = lengths_scaling.unsqueeze(1).repeat((1, x.size(-1)))\n",
        "#         x /= lengths_scaling.to(x.device)        \n",
        "#         x = self.l1(x)                \n",
        "\n",
        "#         x = self.relu(x)\n",
        "#         x = self.l2(x)\n",
        "#         x = self.relu(x)\n",
        "#         x = self.lout(x)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA RAM usage 3558456832\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "DJqgzMuo631f",
        "colab_type": "code",
        "outputId": "3e3247e6-fc12-4dea-cbd8-9abf4f4139b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        }
      },
      "source": [
        "model = DeepAverageNetwork(embedding_matrix=vectors, n_classes=n_classes)\n",
        "model.to(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeepAverageNetwork(\n",
              "  (embedding_layer): Embedding(220907, 300)\n",
              "  (l1): Linear(in_features=300, out_features=256, bias=True)\n",
              "  (lstm): LSTM(300, 64, batch_first=True, bidirectional=True)\n",
              "  (relu): ReLU()\n",
              "  (l2): Linear(in_features=256, out_features=128, bias=True)\n",
              "  (lout): Linear(in_features=128, out_features=28, bias=True)\n",
              "  (drop): Dropout2d(p=0.25, inplace=False)\n",
              "  (linear): Linear(in_features=128, out_features=28, bias=True)\n",
              "  (linear_attn): Linear(in_features=156, out_features=28, bias=True)\n",
              "  (linear_cnn): Linear(in_features=512, out_features=28, bias=True)\n",
              "  (ak): Linear(in_features=128, out_features=28, bias=True)\n",
              "  (aq): Linear(in_features=128, out_features=28, bias=True)\n",
              "  (av): Linear(in_features=128, out_features=28, bias=True)\n",
              "  (conv1): Conv1d(64, 128, kernel_size=(2,), stride=(1,))\n",
              "  (conv2): Conv1d(64, 128, kernel_size=(4,), stride=(1,))\n",
              "  (conv3): Conv1d(64, 128, kernel_size=(6,), stride=(1,))\n",
              "  (conv4): Conv1d(64, 128, kernel_size=(8,), stride=(1,))\n",
              "  (mp1): MaxPool1d(kernel_size=31, stride=31, padding=0, dilation=1, ceil_mode=False)\n",
              "  (mp2): MaxPool1d(kernel_size=29, stride=29, padding=0, dilation=1, ceil_mode=False)\n",
              "  (mp3): MaxPool1d(kernel_size=27, stride=27, padding=0, dilation=1, ceil_mode=False)\n",
              "  (mp4): MaxPool1d(kernel_size=25, stride=25, padding=0, dilation=1, ceil_mode=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "8ZZ7X9FA631n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with torch.no_grad():\n",
        "    pred = model(x.to('cuda'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "uHtAACaS631u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params=model.parameters())\n",
        "\n",
        "# model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "RYHweT5H6311",
        "colab_type": "code",
        "outputId": "746e1dc5-1dfb-4b83-c1db-9612f347ef3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "for instance in list(tqdm._instances):\n",
        "    tqdm._decr_instances(instance)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "D8W4RzM_6319",
        "colab_type": "code",
        "outputId": "0006b0ce-69ec-48f7-935d-2bd1e6dba9cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "epochs = 20\n",
        "# epochs = 5\n",
        "losses = []\n",
        "best_test_loss = 10.\n",
        "\n",
        "test_f1 = []\n",
        "\n",
        "for n_epoch in range(epochs):\n",
        "    \n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "    test_targets = []\n",
        "    test_pred_class = []\n",
        "    \n",
        "    progress_bar = tqdm(total=len(train_loader.dataset), desc='Epoch {}'.format(n_epoch + 1))\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for x, y in train_loader:\n",
        "\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        pred = model(x)\n",
        "        loss = criterion(pred, y)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        train_losses.append(loss.item())\n",
        "        losses.append(loss.item())\n",
        "        \n",
        "        progress_bar.set_postfix(train_loss = np.mean(losses[-500:]))\n",
        "\n",
        "        progress_bar.update(x.shape[0])\n",
        "        \n",
        "    progress_bar.close()\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    for x, y in validation_loader:\n",
        "        \n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "            pred = model(x)\n",
        "\n",
        "            pred = pred.cpu()\n",
        "            y = y.cpu()\n",
        "\n",
        "            test_targets.append(y.numpy())\n",
        "            test_pred_class.append(np.argmax(pred, axis=1))\n",
        "\n",
        "            loss = criterion(pred, y)\n",
        "\n",
        "            test_losses.append(loss.item())\n",
        "        \n",
        "    mean_test_loss = np.mean(test_losses)\n",
        "\n",
        "    test_targets = np.concatenate(test_targets).squeeze()\n",
        "    test_pred_class = np.concatenate(test_pred_class).squeeze()\n",
        "\n",
        "    f1 = f1_score(test_targets, test_pred_class, average='micro')\n",
        "\n",
        "    test_f1.append(f1)\n",
        "    \n",
        "    print()\n",
        "    print('Losses: train - {:.3f}, test - {:.3f}'.format(np.mean(train_losses), mean_test_loss))\n",
        "\n",
        "    print('F1 test - {:.3f}'.format(f1))\n",
        "        \n",
        "    # Early stopping:\n",
        "    if mean_test_loss < best_test_loss:\n",
        "        best_test_loss = mean_test_loss\n",
        "    else:\n",
        "        print('Early stopping')\n",
        "        break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1: 100%|██████████| 599999/599999 [04:04<00:00, 2458.28it/s, train_loss=1.74]\n",
            "Epoch 2:   0%|          | 384/599999 [00:00<04:13, 2362.30it/s, train_loss=1.74]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Losses: train - 1.959, test - 1.535\n",
            "F1 test - 0.558\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2: 100%|██████████| 599999/599999 [04:01<00:00, 2479.85it/s, train_loss=1.66]\n",
            "Epoch 3:   0%|          | 448/599999 [00:00<03:39, 2725.57it/s, train_loss=1.65]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Losses: train - 1.702, test - 1.445\n",
            "F1 test - 0.583\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3: 100%|██████████| 599999/599999 [04:01<00:00, 2489.62it/s, train_loss=1.62]\n",
            "Epoch 4:   0%|          | 384/599999 [00:00<03:43, 2684.91it/s, train_loss=1.62]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Losses: train - 1.649, test - 1.406\n",
            "F1 test - 0.593\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4: 100%|██████████| 599999/599999 [03:58<00:00, 2514.29it/s, train_loss=1.6]\n",
            "Epoch 5:   0%|          | 384/599999 [00:00<03:44, 2674.52it/s, train_loss=1.61]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Losses: train - 1.624, test - 1.385\n",
            "F1 test - 0.598\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5: 100%|██████████| 599999/599999 [03:58<00:00, 2513.28it/s, train_loss=1.58]\n",
            "Epoch 6:   0%|          | 320/599999 [00:00<04:50, 2066.53it/s, train_loss=1.58]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Losses: train - 1.602, test - 1.372\n",
            "F1 test - 0.603\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 6: 100%|██████████| 599999/599999 [04:01<00:00, 2487.68it/s, train_loss=1.57]\n",
            "Epoch 7:   0%|          | 320/599999 [00:00<04:36, 2170.71it/s, train_loss=1.57]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Losses: train - 1.587, test - 1.360\n",
            "F1 test - 0.606\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 7: 100%|██████████| 599999/599999 [04:02<00:00, 2474.27it/s, train_loss=1.55]\n",
            "Epoch 8:   0%|          | 448/599999 [00:00<03:38, 2749.16it/s, train_loss=1.55]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Losses: train - 1.578, test - 1.353\n",
            "F1 test - 0.608\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 8: 100%|██████████| 599999/599999 [04:00<00:00, 2499.08it/s, train_loss=1.55]\n",
            "Epoch 9:   0%|          | 320/599999 [00:00<04:50, 2066.35it/s, train_loss=1.55]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Losses: train - 1.569, test - 1.347\n",
            "F1 test - 0.609\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 9: 100%|██████████| 599999/599999 [04:00<00:00, 2498.52it/s, train_loss=1.54]\n",
            "Epoch 10:   0%|          | 384/599999 [00:00<04:34, 2182.67it/s, train_loss=1.54]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Losses: train - 1.560, test - 1.343\n",
            "F1 test - 0.611\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 10: 100%|██████████| 599999/599999 [04:01<00:00, 2252.23it/s, train_loss=1.54]\n",
            "Epoch 11:   0%|          | 448/599999 [00:00<03:52, 2580.54it/s, train_loss=1.54]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Losses: train - 1.554, test - 1.339\n",
            "F1 test - 0.612\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 11: 100%|██████████| 599999/599999 [04:02<00:00, 2473.45it/s, train_loss=1.53]\n",
            "Epoch 12:   0%|          | 320/599999 [00:00<04:35, 2180.61it/s, train_loss=1.53]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Losses: train - 1.550, test - 1.338\n",
            "F1 test - 0.613\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 12: 100%|██████████| 599999/599999 [03:54<00:00, 2563.84it/s, train_loss=1.53]\n",
            "Epoch 13:   0%|          | 384/599999 [00:00<03:46, 2641.98it/s, train_loss=1.53]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Losses: train - 1.544, test - 1.334\n",
            "F1 test - 0.613\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 13: 100%|██████████| 599999/599999 [03:59<00:00, 2504.17it/s, train_loss=1.52]\n",
            "Epoch 14:   0%|          | 448/599999 [00:00<03:35, 2781.74it/s, train_loss=1.52]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Losses: train - 1.540, test - 1.331\n",
            "F1 test - 0.614\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 14: 100%|██████████| 599999/599999 [04:00<00:00, 2497.13it/s, train_loss=1.51]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Losses: train - 1.535, test - 1.331\n",
            "F1 test - 0.613\n",
            "Early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "qzW_uaJ-632G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.eval()\n",
        "\n",
        "predictions = []\n",
        "\n",
        "for x, _ in test_loader:\n",
        "\n",
        "    x = x.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        pred = model(x)\n",
        "\n",
        "        pred = pred.cpu()\n",
        "        \n",
        "        predictions.append(np.argmax(pred, axis=1))\n",
        "        \n",
        "predictions = np.concatenate(predictions).squeeze()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSdR5FzSOUEm",
        "colab_type": "code",
        "outputId": "436d280c-b77b-4e50-9c00-dcf777ab502a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "for x, y in test_loader:\n",
        "  print(y)\n",
        "  break\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "rGYgZEwm632S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test['main_category'] = predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AazfR0z_r-Xh",
        "colab_type": "code",
        "outputId": "99586979-a9c5-46b7-831a-77bfb89bd9fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "source": [
        "test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>question</th>\n",
              "      <th>main_category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Подскажите сайт российский, вещи заказывать: )...</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Как заказать Рикардо Милоса в Москве?</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Пустят ли меня в Израиль, если я работаю в ОАЭ?</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>почему о наличии пальмового масла и консервато...</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Вот во всех бедах России винят правительство.....</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199995</th>\n",
              "      <td>199995</td>\n",
              "      <td>Какая девушка по характеру? Что происходит вок...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199996</th>\n",
              "      <td>199996</td>\n",
              "      <td>Куда отправиться отдыхать? Дубай или Испания (...</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199997</th>\n",
              "      <td>199997</td>\n",
              "      <td>парсинг запроса к сайту</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199998</th>\n",
              "      <td>199998</td>\n",
              "      <td>Можно ли подать заявление на восстановление ср...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199999</th>\n",
              "      <td>199999</td>\n",
              "      <td>Шагомер на телефоне xiaomi не считает шаги</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         index  ... main_category\n",
              "0            0  ...            15\n",
              "1            1  ...            15\n",
              "2            2  ...            25\n",
              "3            3  ...            17\n",
              "4            4  ...            12\n",
              "...        ...  ...           ...\n",
              "199995  199995  ...             1\n",
              "199996  199996  ...            25\n",
              "199997  199997  ...            14\n",
              "199998  199998  ...             4\n",
              "199999  199999  ...             3\n",
              "\n",
              "[200000 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "82omFpwW632X",
        "colab_type": "code",
        "outputId": "8ba452ea-04c7-4f12-f35e-db02771df661",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        }
      },
      "source": [
        "test = test[['index', 'main_category']]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-8942de4d13b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'main_category'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2999\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3000\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3001\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3002\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3003\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter, raise_missing)\u001b[0m\n\u001b[1;32m   1283\u001b[0m                 \u001b[0;31m# When setting, missing keys are not allowed, even with .loc:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m                 \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"raise_missing\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_setter\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1285\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1286\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m         self._validate_read_indexer(\n\u001b[0;32m-> 1092\u001b[0;31m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1093\u001b[0m         )\n\u001b[1;32m   1094\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1183\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"loc\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1185\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{} not in index\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnot_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m             \u001b[0;31m# we skip the warning on Categorical/Interval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['main_category'] not in index\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQ7QPLhwuY58",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test['question']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "5ZQL3Tym632m",
        "colab_type": "code",
        "outputId": "54886d4b-d442-4405-ddc7-79ec22d9d0de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "test.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>main_category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index  main_category\n",
              "0      0             15\n",
              "1      1             15\n",
              "2      2             25\n",
              "3      3             17\n",
              "4      4             12"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "TzfydXgq632u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test.to_csv('gdrive/My Drive/CompLing/submission.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "hICfi8cH6321",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}